name: "nautilus"
version: "0.4.1"
parallel: parallel
purpose: "Neural Network-Boosted Importance Nested Sampling"
url: "https://github.com/johannesulf/nautilus"
attribution: ["Johannes U. Lange"]

explanation: >
    Nautilus is an MIT-licensed pure-Python package for Bayesian posterior and
    evidence estimation. It utilizes importance sampling and efficient space
    exploration using neural networks. Compared to traditional MCMC and Nested
    Sampling codes, it often needs fewer likelihood calls and produces much
    larger posterior samples. Additionally, nautilus is highly accurate and
    can produce Bayesian evidence estimates with percent precision.


installation: >
    pip install nautilus-sampler
    conda install -c conda-forge nautilus-sampler
    

# List of configuration options for this sampler
params:
    n_live: (integer; default=1500) number of live points
    n_update: (integer; default=n_live) number of additions to the live set before a new bound is created
    enlarge: (float; default=1.1*n_dim) factor by which the volume of ellipsoidal bounds is increased
    n_batch: (integer; default=100) number of likelihood evaluations that are performed at each step
    random_state: (int; default=-1) random seed, negative values give a random random seed
    filepath: (string; default='None') file used for checkpointing, must have .hdf5 ending
    resume: (bool; default=True) if True, resume from previous run stored in `filepath`
    f_live: (float; default=0.01) live set evidence fraction when exploration phase terminates
    n_shell: (int; default=n_batch) minimum number of points in each shell
    n_eff: (float; default=10000.0) minimum effective sample size
    discard_exploration: (bool; default=False) whether to discard points drawn in the exploration phase
    verbose: (bool; default=False) If true, print information about sampler progress
